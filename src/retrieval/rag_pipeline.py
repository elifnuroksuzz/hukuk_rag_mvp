#!/usr/bin/env python3
"""
RAG Pipeline - Retrieval-Augmented Generation sistemi
"""

import os
import sys
from typing import List, Dict, Any, Optional
from datetime import datetime
import yaml
from loguru import logger
from openai import OpenAI

# Local imports
sys.path.append('src')
from database.chroma_manager import ChromaManager

class RAGPipeline:
    """RAG Pipeline ana sÄ±nÄ±fÄ±"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        """BaÅŸlatma"""
        self.config = self._load_config(config_path)
        self.chroma_manager = ChromaManager(config_path)
        self.llm_client = None
        
        # LLM client'Ä± baÅŸlat
        self._initialize_llm()
        
        logger.info("RAG Pipeline baÅŸlatÄ±ldÄ±")
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """KonfigÃ¼rasyon yÃ¼kle"""
        try:
            with open(config_path, 'r', encoding='utf-8') as file:
                return yaml.safe_load(file)
        except Exception as e:
            logger.error(f"Config yÃ¼klenemedi: {e}")
            return self._default_config()
    
    def _default_config(self) -> Dict[str, Any]:
        """VarsayÄ±lan config"""
        return {
            'llm': {
                'provider': 'huggingface',
                'base_url': 'https://router.huggingface.co/v1',
                'model': 'openai/gpt-oss-120b:novita',
                'temperature': 0.1,
                'max_tokens': 1000
            },
            'retrieval': {
                'top_k': 5,
                'similarity_threshold': 0.7
            }
        }
    
    def _initialize_llm(self):
        """LLM client'Ä± baÅŸlat"""
        try:
            from dotenv import load_dotenv
            load_dotenv()
            
            # HuggingFace Router iÃ§in OpenAI compatible client
            self.llm_client = OpenAI(
                base_url=os.getenv("BASE_URL", self.config['llm']['base_url']),
                api_key=os.getenv("API_KEY", "dummy_key")
            )
            
            logger.info(f"LLM client baÅŸlatÄ±ldÄ±: {self.config['llm']['model']}")
            
        except Exception as e:
            logger.error(f"LLM baÅŸlatma hatasÄ±: {e}")
            raise
    
    def query(self, question: str, chat_history: Optional[List[Dict]] = None) -> Dict[str, Any]:
        """Ana RAG sorgu fonksiyonu"""
        try:
            logger.info(f"ğŸ” Sorgu: {question}")
            
            # 1. Retrieval - Ä°lgili belgeleri bul
            relevant_docs = self.chroma_manager.search(
                question, 
                n_results=self.config['retrieval']['top_k']
            )
            
            if not relevant_docs:
                return {
                    'answer': 'ÃœzgÃ¼nÃ¼m, sorunuzla ilgili belge bulamadÄ±m. LÃ¼tfen daha spesifik bir soru sormayÄ± deneyin.',
                    'sources': [],
                    'confidence': 0.0,
                    'query': question,
                    'timestamp': datetime.now().isoformat()
                }
            
            # 2. Context hazÄ±rla
            context = self._prepare_context(relevant_docs)
            
            # 3. Prompt oluÅŸtur
            prompt = self._create_prompt(question, context, chat_history)
            
            # 4. LLM'den cevap al
            llm_response = self._get_llm_response(prompt)
            
            # 5. Sonucu formatla
            result = {
                'answer': llm_response,
                'sources': self._format_sources(relevant_docs),
                'confidence': self._calculate_confidence(relevant_docs),
                'query': question,
                'timestamp': datetime.now().isoformat(),
                'retrieved_docs_count': len(relevant_docs)
            }
            
            logger.success(f"âœ… Sorgu tamamlandÄ±: {len(llm_response)} karakter cevap")
            return result
            
        except Exception as e:
            logger.error(f"RAG sorgu hatasÄ±: {e}")
            return {
                'answer': f'ÃœzgÃ¼nÃ¼m, sorunuzu iÅŸlerken bir hata oluÅŸtu: {str(e)}',
                'sources': [],
                'confidence': 0.0,
                'query': question,
                'timestamp': datetime.now().isoformat()
            }
    
    def _prepare_context(self, relevant_docs: List[Dict]) -> str:
        """Context metni hazÄ±rla"""
        context_parts = []
        
        for i, doc in enumerate(relevant_docs):
            # Similarity threshold kontrolÃ¼
            similarity = doc.get('similarity', 0)
            threshold = self.config['retrieval']['similarity_threshold']
            
            if similarity < threshold:
                continue
            
            # Context formatÄ±
            source_info = f"[Kaynak {i+1}: {doc['metadata']['filename']}]"
            content = doc['content'].strip()
            
            context_parts.append(f"{source_info}\n{content}\n")
        
        return "\n".join(context_parts)
    
    def _create_prompt(self, question: str, context: str, chat_history: Optional[List[Dict]] = None) -> str:
        """LLM iÃ§in prompt oluÅŸtur"""
        
        # Sistem mesajÄ±
        system_prompt = """Sen uzman bir TÃ¼rk hukuk asistanÄ±sÄ±n. GÃ¶revin:

1. Verilen hukuki belgelerden yararlanarak kullanÄ±cÄ±nÄ±n sorularÄ±nÄ± yanÄ±tlamak
2. Sadece verilen belgeler temelinde cevap vermek
3. YanÄ±tlarÄ±nÄ± net, anlaÅŸÄ±lÄ±r ve hukuki aÃ§Ä±dan doÄŸru ÅŸekilde sunmak
4. EÄŸer belgeler yetersizse bunu belirtmek
5. Kaynak referanslarÄ±nÄ± gÃ¶stermek

KURALLARIN:
- Sadece verilen belgelerdeki bilgileri kullan
- SpekÃ¼lasyon yapma
- Belirsizlik durumunda "Bu konuda verilen belgelerde yeterli bilgi bulunmuyor" de
- TÃ¼rkÃ§e dilbilgisi kurallarÄ±na uygun yanÄ±t ver
- Hukuki terimler kullanÄ±rken aÃ§Ä±klama yap"""

        # Chat history varsa ekle
        history_context = ""
        if chat_history:
            history_parts = []
            for msg in chat_history[-3:]:  # Son 3 mesaj
                role = "KullanÄ±cÄ±" if msg.get('role') == 'user' else "Asistan"
                content = msg.get('content', '')
                history_parts.append(f"{role}: {content}")
            
            if history_parts:
                history_context = f"\nÃ–nceki konuÅŸma:\n" + "\n".join(history_parts) + "\n"
        
        # Ana prompt
        user_prompt = f"""Hukuki belgeler:
{context}

{history_context}
KullanÄ±cÄ± sorusu: {question}

LÃ¼tfen bu soruyu sadece verilen hukuki belgelere dayanarak yanÄ±tla. Kaynak referanslarÄ±nÄ± da belirt."""

        return system_prompt + "\n\n" + user_prompt
    
    def _get_llm_response(self, prompt: str) -> str:
        """LLM'den cevap al"""
        try:
            response = self.llm_client.chat.completions.create(
                model=self.config['llm']['model'],
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=self.config['llm']['temperature'],
                max_tokens=self.config['llm']['max_tokens']
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"LLM response hatasÄ±: {e}")
            
            # Fallback: Alternatif model dene
            try:
                alt_model = self.config['llm'].get('alternative_model')
                if alt_model:
                    response = self.llm_client.chat.completions.create(
                        model=alt_model,
                        messages=[{"role": "user", "content": prompt}],
                        temperature=self.config['llm']['temperature'],
                        max_tokens=self.config['llm']['max_tokens']
                    )
                    return response.choices[0].message.content.strip()
            except:
                pass
            
            return "LLM yanÄ±t vermedi. LÃ¼tfen daha sonra tekrar deneyin."
    
    def _format_sources(self, relevant_docs: List[Dict]) -> List[Dict]:
        """Kaynak bilgilerini formatla"""
        sources = []
        
        for doc in relevant_docs:
            similarity = doc.get('similarity', 0)
            threshold = self.config['retrieval']['similarity_threshold']
            
            if similarity < threshold:
                continue
            
            source = {
                'filename': doc['metadata']['filename'],
                'similarity': f"{similarity:.2f}",
                'chunk_index': doc['metadata'].get('chunk_index', 0),
                'preview': doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content']
            }
            sources.append(source)
        
        return sources
    
    def _calculate_confidence(self, relevant_docs: List[Dict]) -> float:
        """Cevap gÃ¼ven skorunu hesapla"""
        if not relevant_docs:
            return 0.0
        
        # En iyi similarity skorunu al
        best_similarity = max(doc.get('similarity', 0) for doc in relevant_docs)
        
        # Threshold Ã¼zerindeki doc sayÄ±sÄ±
        threshold = self.config['retrieval']['similarity_threshold']
        good_docs = sum(1 for doc in relevant_docs if doc.get('similarity', 0) >= threshold)
        
        # Confidence skoru hesapla (0-1 arasÄ±)
        base_confidence = min(best_similarity, 1.0)
        doc_bonus = min(good_docs * 0.1, 0.3)  # Max 0.3 bonus
        confidence = min(base_confidence + doc_bonus, 1.0)
        
        return round(confidence, 2)
    
    def get_stats(self) -> Dict[str, Any]:
        """Pipeline istatistikleri"""
        chroma_stats = self.chroma_manager.get_stats()
        
        return {
            **chroma_stats,
            'llm_model': self.config['llm']['model'],
            'retrieval_top_k': self.config['retrieval']['top_k'],
            'similarity_threshold': self.config['retrieval']['similarity_threshold']
        }


# Test fonksiyonu
def test_rag_pipeline():
    """RAG Pipeline test fonksiyonu"""
    print("ğŸ§ª RAG Pipeline Testi BaÅŸlÄ±yor...")
    
    try:
        # Pipeline oluÅŸtur
        rag = RAGPipeline()
        
        # Test sorularÄ±
        test_questions = [
            "TÃ¼rk Ceza Kanunu'nun amacÄ± nedir?",
            "Medeni Kanun'da hakim nasÄ±l karar verir?",
            "Ä°cra takibi nasÄ±l baÅŸlar?",
            "Ã–deme emrine itiraz edilebilir mi?",
            "Bu kanunlar ne zaman yÃ¼rÃ¼rlÃ¼ÄŸe girdi?"
        ]
        
        print(f"ğŸ“Š Pipeline istatistikleri:")
        stats = rag.get_stats()
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        print(f"\nğŸ” {len(test_questions)} test sorusu Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
        
        for i, question in enumerate(test_questions, 1):
            print(f"\n--- Test {i} ---")
            print(f"â“ Soru: {question}")
            
            result = rag.query(question)
            
            print(f"âœ… Cevap ({result['confidence']} gÃ¼ven): {result['answer'][:200]}...")
            print(f"ğŸ“š {len(result['sources'])} kaynak kullanÄ±ldÄ±")
            
            if result['sources']:
                print(f"ğŸ“„ Ana kaynak: {result['sources'][0]['filename']}")
        
        print("\nâœ… RAG Pipeline testi baÅŸarÄ±lÄ±!")
        return True
        
    except Exception as e:
        print(f"âŒ RAG Pipeline test hatasÄ±: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    test_rag_pipeline()